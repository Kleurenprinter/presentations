{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " $('div.output_prompt').show();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " $('div.output_prompt').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " $('div.output_prompt').show();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " $('div.output_prompt').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Artifical Neural Network Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/TensorFlow.jpg\" width=\"25%\" align=\"right\">\n",
    "\n",
    "# TensorFlow\n",
    "\n",
    "- python Library\n",
    "- released November 2015\n",
    "- second generation machine learning system of Google Brain\n",
    "- C++ back-end for fast computations\n",
    "- currently only unix-based\n",
    "\n",
    "<img src=\"images/tf_git.png\" width=\"100%\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/tflearn.png\" width=\"25%\" align=\"right\">\n",
    "\n",
    "# TFLearn\n",
    "\n",
    "- high-level API for TensorFlow\n",
    "- released March 2016\n",
    "- easy-to-use and transparent\n",
    "\n",
    "<img src=\"images/tflearn_git.png\" width=\"100%\" align=\"right\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image Datasets\n",
    "\n",
    "<img src=\"images/image_lib.jpg\" width='100%' align=\"right\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/CIFAR10.png\" width='25%' align=\"right\">\n",
    "\n",
    "# CIFAR 10\n",
    "\n",
    "- 60000 $32 \\times 32$ colour images\n",
    "- 10 classes $\\rightarrow$ 6000 images per class\n",
    "- 5 training batches, 1 test batch for *every* class\n",
    "\n",
    "\n",
    "Collected for **MSc thesis** \n",
    "\n",
    "<ul>\n",
    "<a href=\"learning-features-2009-TR.pdf\">Learning Multiple Layers of Features from Tiny Images</a>, Alex Krizhevsky, 2009.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/CIFAR100.png\" width=\"25%\" align=\"right\">\n",
    "\n",
    "# CIFAR 100\n",
    "\n",
    "\n",
    "- 60000 $32 \\times 32$ colour images\n",
    "- 100 classes $\\rightarrow$ 600 images per class\n",
    "- 20 superclasses $\\rightarrow$ 3000 images per superclass\n",
    "\n",
    "- 5 training batches, 1 test batch for *every* class\n",
    "\n",
    "\n",
    "Collected for **MSc thesis** \n",
    "\n",
    "<ul>\n",
    "<a href=\"learning-features-2009-TR.pdf\">Learning Multiple Layers of Features from Tiny Images</a>, Alex Krizhevsky, 2009.\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Practical Use-Case\n",
    " \n",
    "Human classifier: Detect whether a picture contains a human\n",
    " \n",
    " - Built upon CIFAR-100 dataset\n",
    " - Two labels: 'human' and 'no human'\n",
    "\n",
    "Enriched with:\n",
    "\n",
    "- Frames Labeled In Cinema (**FLIC**): 3528 pictures (1026 test)\n",
    "- Labeled Faces in the Wild (**LFW**): 13233 pictures (2000 test)\n",
    " \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " <img src=\"images/FLIC.gif\" height=\"50%\" align=\"right\">\n",
    " <img src=\"images/LFW.gif\" height=\"50%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Building\n",
    "<img src=\"images/inception.png\" width='100%' align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data loading and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np\n",
    "from CIFAR100 import get_cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import data into numpy array\n",
    "datapath =  \"/home/data/jclauw/workspace/tensorflow/CIFAR100/cifar-100-python/\" \n",
    "tr_data100, tr_clabels100, tr_flabels100, te_data100, te_clabels100, te_flabels100, clabel_names100, flabel_names100 = get_cifar100(datapath)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape numpy array\n",
    "tr_cifar100 = tr_data100.reshape(50000,32,32,3)/255\n",
    "te_cifar100 = te_data100.reshape(10000,32,32,3)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Change labels\n",
    "te_labels = np.array([0 if u!= 14 else 1 for u in te_clabels100])\n",
    "tr_labels = np.array([0 if u!= 14 else 1 for u in tr_clabels100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import data from LFW and FLIC database\n",
    "XtrainLFW, YtrainLFW = tflearn.data_utils.image_dirs_to_samples(directory='/home/data/jclauw/workspace/tensorflow/CIFAR100/faces1/', resize=(32,32), filetypes=['.jpg','.png','.jpeg'])\n",
    "\n",
    "XtestLFW, YtestLFW = tflearn.data_utils.image_dirs_to_samples(directory='/home/data/jclauw/workspace/tensorflow/CIFAR100/faces1Test/', resize=(32,32), filetypes=['.jpg','.png','.jpeg'])\n",
    "\n",
    "XtrainFLIC, YtrainFLIC = tflearn.data_utils.image_dirs_to_samples(directory='/home/data/jclauw/workspace/tensorflow/CIFAR100/poses/', resize=(32,32), filetypes=['.jpg','.png','.jpeg'])\n",
    "\n",
    "XtestFLIC, YtestFLIC = tflearn.data_utils.image_dirs_to_samples(directory='/home/data/jclauw/workspace/tensorflow/CIFAR100/posesTest/', resize=(32,32), filetypes=['.jpg','.png','.jpeg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Asign data to parameters\n",
    "(X, Y), (X_test, Y_test) = (Xtrdata, Ytrdata) , (Xtedata, Ytedata)\n",
    "# Shuffle data\n",
    "X, Y = shuffle(X, Y)\n",
    "# Changes simple integer data (0: not human, 1: human) to one hot data for every image \n",
    "Y = to_categorical(Y, 2)\n",
    "Y_test = to_categorical(Y_test, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizes and centers data\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Adds different variations for pictures: blurring, rotation\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Building a convolutional neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convolutional network building\n",
    "# Network initialization\n",
    "network = input_data(shape=[None, 32, 32, 3],\n",
    "                     data_preprocessing=img_prep,\n",
    "                     data_augmentation=img_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1st layer: Convolutional\n",
    "network = conv_2d(network, 32, 3, activation='Relu')\n",
    "# 2nd layer: Max pooling\n",
    "network = max_pool_2d(network, 2)\n",
    "# 3rd layer: Convolutional\n",
    "network = conv_2d(network, 64, 3, activation='Relu')\n",
    "# 4th layer: Convolutional\n",
    "network = conv_2d(network, 64, 3, activation='Relu')\n",
    "# 5th layer: Max pooling\n",
    "network = max_pool_2d(network, 2)\n",
    "# 6th layer: Fully connected\n",
    "network = fully_connected(network, 512, activation='Relu')\n",
    "# 7th layer: Dropout\n",
    "network = dropout(network, 0.5)\n",
    "# 8th layer: Fully connected, softmax activation\n",
    "network = fully_connected(network, 2, activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Asign network to deep neural network model\n",
    "model = tflearn.DNN(network, tensorboard_verbose=3, tensorboard_dir=\"~/Documents/tf_logs\")\n",
    "# Fit model\n",
    "model.fit(X, Y, n_epoch=15, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=96, run_id='cifar100_human_recognition_new_15ep_Relu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent  variants\n",
    "<img src=\"images/gradient.png\" width='100%' align=\"right\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss function\n",
    "$$\n",
    " \\min_\\boldsymbol{\\theta} \\sum_{i=1}^n \\mathcal{L}_i(y_i, f(\\mathbf{x}_i| \\boldsymbol{\\theta}))\\, = J(\\theta)\n",
    "$$\n",
    "\n",
    "#### Batch Gradient descent\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J( \\theta)$$\n",
    "\n",
    "\n",
    "#### Stochastic Gradient descent\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J( \\theta; x^{(i)}; y^{(i)})$$\n",
    "\n",
    "\n",
    "#### Mini-batch Gradient descent\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J( \\theta; x^{(i:i+n)}; y^{(i:i+n)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Momentum\n",
    "\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta)$$\n",
    "\n",
    "$$ \\theta = \\theta - v_t $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/wm.gif\" width=\"45%\" align=\"left\">\n",
    "<img src=\"images/withm.gif\" width=\"45%\" align=\"right\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nesterov accelerated gradient\n",
    "\n",
    "\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta - \\gamma v_{t-1})$$\n",
    "\n",
    "$$ \\theta = \\theta - v_t $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/nag.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adagrad\n",
    "\n",
    "\n",
    "\n",
    "$$ g_{t, i} = \\nabla_\\theta J( \\theta_i ) $$\n",
    "\n",
    "$$ \\theta_{t+1, i} = \\theta_{t, i} - \\dfrac{\\eta}{\\sqrt{G_{t, ii} + \\epsilon}} \\cdot \\nabla_\\theta J( \\theta_i )  $$\n",
    "\n",
    "#### **where:**   \n",
    "$$G_{t} \\in \\mathbb{R}^{d \\times d}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adadelta\n",
    "\n",
    "- Extension of Adagrad which reduces monotonically decreasing learning rate, preventing a decreasing performance of the model\n",
    "\n",
    "\n",
    "## Adam\n",
    "\n",
    "- Further extension on Keeps average of both squared and decaying average keeps past gradients (similarly to momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/gradTop.gif\" width=\"50%\" align='left'>\n",
    "<img src=\"images/gradSaddle.gif\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output TensorFlow\n",
    "<img src=\"images/result.png\" width=\"100%\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Is this a good model for the detection of humans?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "| | Predicted no human  | Predicted human |\n",
    "|---|---------------|-----------|----|\n",
    "|  **True no human** | 9485 | 447 |\n",
    "| **True human** | 15 | 2378 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
